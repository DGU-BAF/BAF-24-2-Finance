{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting urllib3<3,>=1.26 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi>=2021.10.8 (from selenium)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from selenium) (4.12.2)\n",
      "Collecting websocket-client~=1.8 (from selenium)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting idna (from trio~=0.17->selenium)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=1.14 (from trio~=0.17->selenium)\n",
      "  Downloading cffi-1.17.1-cp311-cp311-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->trio~=0.17->selenium)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.25.0-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.7 MB 10.9 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.1/9.7 MB 11.8 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.6/9.7 MB 12.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.1/9.7 MB 12.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.7/9.7 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.3/9.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.9/9.7 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.5/9.7 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.1/9.7 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.5/9.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.1/9.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.6/9.7 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.3/9.7 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.8/9.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.7 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.0/9.7 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.6/9.7 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "   ---------------------------------------- 0.0/167.3 kB ? eta -:--:--\n",
      "   ---------------------------------------  163.8/167.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 167.3/167.3 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
      "   ---------------------------------------- 0.0/481.7 kB ? eta -:--:--\n",
      "   --------------------------------------  481.3/481.7 kB 14.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  481.3/481.7 kB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 481.7/481.7 kB 6.0 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.3 kB ? eta -:--:--\n",
      "   -------------------------------------- - 122.9/126.3 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 126.3/126.3 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 51.2/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.0 kB ? eta -:--:--\n",
      "   ---------------------------------------  61.4/63.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.0/63.0 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading cffi-1.17.1-cp311-cp311-win_amd64.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.4 kB ? eta -:--:--\n",
      "   ------------------------------------- - 174.1/181.4 kB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 181.4/181.4 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "   ---------------------------------------- 0.0/70.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 70.4/70.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 51.2/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "   ---------------------------------------- 0.0/117.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 117.6/117.6 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: sortedcontainers, websocket-client, urllib3, sniffio, pysocks, pycparser, idna, h11, certifi, attrs, wsproto, outcome, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-24.2.0 certifi-2024.8.30 cffi-1.17.1 h11-0.14.0 idna-3.10 outcome-1.3.0.post0 pycparser-2.22 pysocks-1.7.1 selenium-4.25.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.27.0 trio-websocket-0.11.1 urllib3-2.2.3 websocket-client-1.8.0 wsproto-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\USER\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래 지은 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.action_chains import ActionChains\n",
    "# import time\n",
    "# import csv\n",
    "\n",
    "# # ChromeDriver 경로 설정\n",
    "# chrome_driver_path = \"C:/Users/USER/Desktop/MBA_정호원/chromedriver-win64/chromedriver.exe\"\n",
    "\n",
    "# # WebDriver 옵션 설정\n",
    "# options = Options()\n",
    "# options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36\")\n",
    "\n",
    "# # WebDriver 초기화\n",
    "# service = Service(chrome_driver_path)\n",
    "# driver = webdriver.Chrome(service=service, options=options)\n",
    "# driver.implicitly_wait(5)  # 대기 시간 5초 설정\n",
    "\n",
    "# # 페이지 불러오기\n",
    "# driver.get('https://www.wanted.co.kr/wdlist/523?country=kr&job_sort=job.latest_order&years=-1&locations=all')  # 직무 선택된 URL\n",
    "\n",
    "# # 자동 스크롤 기능 구현\n",
    "# def scroll_to_bottom():\n",
    "#     last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#     while True:\n",
    "#         driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#         time.sleep(2)  # 페이지 로드 대기\n",
    "#         new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#         if new_height == last_height:\n",
    "#             break\n",
    "#         last_height = new_height\n",
    "#     time.sleep(5)  # 추가 대기 시간 (페이지가 완전히 로드될 때까지 기다림)\n",
    "\n",
    "# # 스크롤을 끝까지 내린다\n",
    "# scroll_to_bottom()\n",
    "\n",
    "# # 공고 리스트의 모든 링크를 저장 (스크롤 후 모든 공고 리스트 가져오기)\n",
    "# # 원래 알고리즘: 카드 번호 순서대로 들어가기\n",
    "# # 원래 알고리즘 문제점: 전체 로드 해놔도 인식을 못함. 맨 위에 몇개만 가져오고 오류.\n",
    "# # 바꾼 알고리즘: 전체 로드 후, 카드의 url 저장해서 하나하나 들어가기\n",
    "\n",
    "# job_links = driver.find_elements(By.CSS_SELECTOR, 'ul.List_List__Ni_dK li a')\n",
    "# job_urls = [job.get_attribute('href') for job in job_links]  # 모든 공고의 링크를 저장\n",
    "\n",
    "# # 페이지 상단으로 다시 스크롤\n",
    "# driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "\n",
    "# try:\n",
    "#     # 수집한 데이터를 CSV로 작성할 때, UTF-8 인코딩 확인\n",
    "#     with open(\"C:/Users/USER/Desktop/MBA_정호원/원티드 채용공고_마케팅.csv\", 'w', newline='', encoding='utf-8-sig') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow(['채용공고명', '포지션 상세', '주요 업무', '자격 요건', '우대사항', '혜택 및 복지', '채용 전형', '위치', '마감일', '태그', '회사명'])  # CSV 헤더 설정\n",
    "\n",
    "#         for job_url in job_urls:\n",
    "#             try:\n",
    "#                 driver.get(job_url)\n",
    "#                 time.sleep(2)  # 페이지 로딩 대기\n",
    "\n",
    "#                 try:\n",
    "#                     tags_ul = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[2]/ul')  # ul 리스트에서 모든 li 태그 선택\n",
    "#                     tags = [tag.text for tag in tags_ul]  \n",
    "#                     tags_text = ', '.join(tags)  \n",
    "#                 except:\n",
    "#                     tags_text = \"\"\n",
    "\n",
    "#                 try:\n",
    "#                     location = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/header/div/div[1]/span[2]').text\n",
    "#                 except:\n",
    "#                     location = \"\"\n",
    "\n",
    "#                 try:\n",
    "#                     more_button = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/button')\n",
    "#                     more_button.click()\n",
    "#                     time.sleep(1)  # 페이지 로딩 대기\n",
    "#                 except:\n",
    "#                     print(f\"No '상세 정보 더 보기' button for job: {job_url}. Continuing...\")\n",
    "\n",
    "#                 # 필요한 정보 수집 (이게 공고마다 다 달라서 없으면 빈문자열로 받도록 처리헸습니다)\n",
    "#                 # 더 필요한 항목이 있다면 추가하여 수정 후 push 부탁드립니다\n",
    "#                 try:\n",
    "#                     title = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/header/h1').text\n",
    "#                 except:\n",
    "#                     title = \"\"\n",
    "\n",
    "#                 try:\n",
    "#                     details = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/p/span').text\n",
    "#                 except:\n",
    "#                     details = \"\"\n",
    "\n",
    "#                 try:\n",
    "#                     main_tasks = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[1]/p').text\n",
    "#                 except:\n",
    "#                     main_tasks = \"\"\n",
    "\n",
    "#                 try:\n",
    "#                     qualifications = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[2]/p').text\n",
    "#                 except:\n",
    "#                     qualifications = \"\"\n",
    "\n",
    "#                 try:\n",
    "#                     preferred = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[3]/p').text\n",
    "#                 except:\n",
    "#                     preferred = \"\"\n",
    "\n",
    "#                 try:\n",
    "#                     benefits = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[4]/p').text\n",
    "#                 except:\n",
    "#                     benefits = \"\"\n",
    "\n",
    "#                 try:\n",
    "#                     process = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[5]/p').text\n",
    "#                 except:\n",
    "#                     process = \"\"\n",
    "\n",
    "#                 try:\n",
    "#                     deadline = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[3]/span').text\n",
    "#                 except:\n",
    "#                     deadline = \"\"\n",
    "\n",
    "#                 try:\n",
    "#                     company_name = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/header/div/div[1]/a').text\n",
    "#                 except:\n",
    "\n",
    "#                 # 수집한 데이터를 CSV 파일에 작성\n",
    "#                 writer.writerow([title, details, main_tasks, qualifications, preferred, benefits, process, location, deadline, tags_text, company_name])\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing job {job_url}: {e}\")\n",
    "\n",
    "# finally:\n",
    "#     driver.quit()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 버튼 full Xpath\n",
    "/html/body/div[1]/main/div[1]/div/section/section/article[1]/div/button/span[2]\n",
    "- 버튼 general Xpath\n",
    "//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/button/span[2]\n",
    "- 버튼\n",
    "//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/button\n",
    "\n",
    "- 자격요건\n",
    "//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[1]/p/span\n",
    "\n",
    "- 우대사항\n",
    "//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[3]/p/span\n",
    "\n",
    "- 혜택 및 복지\n",
    "//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[4]/p/span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.common.by import By\n",
    "# import time\n",
    "# import csv\n",
    "\n",
    "# # ChromeDriver 경로 설정\n",
    "# chrome_driver_path = \"C:/Users/USER/Desktop/MBA_정호원/chromedriver-win64/chromedriver.exe\"\n",
    "\n",
    "# # WebDriver 옵션 설정\n",
    "# options = Options()\n",
    "# options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36\")\n",
    "\n",
    "# # WebDriver 초기화\n",
    "# service = Service(chrome_driver_path)\n",
    "# driver = webdriver.Chrome(service=service, options=options)\n",
    "# driver.implicitly_wait(5)  # 대기 시간 5초 설정\n",
    "\n",
    "# # 페이지 불러오기\n",
    "# driver.get('https://www.wanted.co.kr/wdlist/523?country=kr&job_sort=job.recommend_order&years=-1&locations=all')  # 직무 선택된 URL\n",
    "\n",
    "# # 자동 스크롤 기능 구현\n",
    "# def scroll_to_bottom():\n",
    "#     last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#     while True:\n",
    "#         driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#         time.sleep(2)  # 페이지 로드 대기\n",
    "#         new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#         if new_height == last_height:\n",
    "#             break\n",
    "#         last_height = new_height\n",
    "#     time.sleep(5)  # 추가 대기 시간 (페이지가 완전히 로드될 때까지 기다림)\n",
    "\n",
    "# # 스크롤을 끝까지 내린다\n",
    "# scroll_to_bottom()\n",
    "\n",
    "# # 공고 리스트의 모든 링크를 저장 (스크롤 후 모든 공고 리스트 가져오기)\n",
    "# job_links = driver.find_elements(By.CSS_SELECTOR, 'ul.List_List__Ni_dK li a')\n",
    "# job_urls = [job.get_attribute('href') for job in job_links]  # 모든 공고의 링크를 저장\n",
    "\n",
    "# # 페이지 상단으로 다시 스크롤\n",
    "# driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "\n",
    "# try:\n",
    "#     # 수집한 데이터를 CSV로 작성할 때, UTF-8 인코딩 확인\n",
    "#     with open(\"C:/Users/USER/Desktop/MBA_정호원/원티드_채용공고_마케팅_5개.csv\", 'w', newline='', encoding='utf-8-sig') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow(['채용공고명', '포지션 상세', '주요 업무', '자격 요건', '우대사항', '혜택 및 복지', '채용 전형', '태그', '마감일', '면접리뷰', '회사위치', '회사명'])  # CSV 헤더 설정\n",
    "\n",
    "#         # 첫 5개 공고만 수집\n",
    "#         for job_url in job_urls[:5]:  # 첫 5개 공고만 처리\n",
    "#             try:\n",
    "#                 driver.get(job_url)\n",
    "#                 time.sleep(3)  # 페이지 로딩 대기\n",
    "\n",
    "#                 # \"상세 정보 더 보기\" 버튼 클릭 (JavaScript 사용)\n",
    "#                 try:\n",
    "#                     button_element = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/button/span[1]')\n",
    "#                     driver.execute_script(\"arguments[0].click();\", button_element)\n",
    "#                     time.sleep(2)  # 버튼 클릭 후 대기\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"'상세 정보 더 보기' 버튼 클릭 실패: {job_url}. Continuing... {e}\")\n",
    "\n",
    "#                 # 채용공고명\n",
    "#                 try:\n",
    "#                     title = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/header/h1').text\n",
    "#                 except:\n",
    "#                     title = \"\"\n",
    "\n",
    "#                 # 포지션 상세\n",
    "#                 try:\n",
    "#                     details = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/p/span').text\n",
    "#                 except:\n",
    "#                     details = \"\"\n",
    "\n",
    "#                 # 주요 업무\n",
    "#                 try:\n",
    "#                     main_tasks = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[1]/p').text\n",
    "#                 except:\n",
    "#                     main_tasks = \"\"\n",
    "\n",
    "#                 # 자격 요건\n",
    "#                 try:\n",
    "#                     qualifications = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[1]/p/span').text\n",
    "#                 except:\n",
    "#                     qualifications = \"\"\n",
    "\n",
    "#                 # 우대사항\n",
    "#                 try:\n",
    "#                     preferred = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[3]/p/span').text\n",
    "#                 except:\n",
    "#                     preferred = \"\"\n",
    "\n",
    "#                 # 혜택 및 복지\n",
    "#                 try:\n",
    "#                     benefits = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[4]/p/span').text\n",
    "#                 except:\n",
    "#                     benefits = \"\"\n",
    "\n",
    "#                 # 채용 전형\n",
    "#                 try:\n",
    "#                     process = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[5]/p').text\n",
    "#                 except:\n",
    "#                     process = \"\"\n",
    "\n",
    "#                 # 태그 정보 추출\n",
    "#                 try:\n",
    "#                     tags_ul = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[2]/ul/li')\n",
    "#                     tags = [tag.text for tag in tags_ul]  \n",
    "#                     tags_text = ', '.join(tags)  # 태그를 ,로 연결\n",
    "#                 except:\n",
    "#                     tags_text = \"\"\n",
    "\n",
    "#                 # 마감일\n",
    "#                 try:\n",
    "#                     deadline = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[3]/span').text\n",
    "#                 except:\n",
    "#                     deadline = \"\"\n",
    "\n",
    "#                 # 면접 리뷰 정보 추출\n",
    "#                 try:\n",
    "#                     interview_review_elements = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[4]\n",
    "#                     ul/li/span')\n",
    "#                     interview_reviews = [review.text for review in interview_review_elements]\n",
    "#                     interview_review_text = ', '.join(interview_reviews)  # ,로 연결\n",
    "#                 except:\n",
    "#                     interview_review_text = \"\"\n",
    "\n",
    "#                 # 위치 정보 추출\n",
    "#                 try:\n",
    "#                     location = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[5]/div/div[2]/span')\n",
    "#                     text\n",
    "#                 except:\n",
    "#                     # 대체 위치 정보 추출\n",
    "#                     try:\n",
    "#                         location = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/header/div/div[1]/span[2]').text\n",
    "                        \n",
    "#                     except:\n",
    "#                         location = \"위치 정보 없음\"  # 위치가 없을 경우 기본값 설정\n",
    "\n",
    "#                 # 회사명\n",
    "#                 try:\n",
    "#                     company_name = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/header/div/div[1]/a').text\n",
    "#                 except:\n",
    "#                     company_name = \"\"\n",
    "\n",
    "#                 # 수집한 데이터를 CSV 파일에 작성\n",
    "#                 writer.writerow([title, details, main_tasks, qualifications, preferred, benefits, process, tags_text, deadline, interview_review_text, location, company_name])\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing job {job_url}: {e}\")\n",
    "\n",
    "# finally:\n",
    "#     driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "호원 코드 수정 - 마케팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변경사항\n",
    "\n",
    "- 위치 -> 근무 지역으로 구체화 / 없으면 그냥 위치 정보 출력\n",
    "- 버튼 정보\n",
    "1. 상세정보 버튼 XPath 변경 -> 그래도 되지 않았음\n",
    "2. 버튼 예외처리 추가 -> 다양한 Xpath를 가지고 와서 예외처리를 하였음\n",
    "3. 그래도 안되네??\"\n",
    "4. \"상세 정보 더 보기\" 버튼을 JavaScript로 클릭하고 정보 추출\n",
    "- 면접 리뷰 열 추가\n",
    "- 면접 리뷰를 ,로 연결\n",
    "- 태크를 ,로 연결\n",
    "- 오류 발생 방지를 위해 열 이름 순서 조정 -> try/except 문도 같이 수정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# ChromeDriver 경로 설정\n",
    "chrome_driver_path = \"C:/Users/USER/Desktop/MBA_정호원/chromedriver-win64/chromedriver.exe\"\n",
    "\n",
    "# WebDriver 옵션 설정\n",
    "options = Options()\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36\")\n",
    "\n",
    "# WebDriver 초기화\n",
    "service = Service(chrome_driver_path)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.implicitly_wait(5)  # 대기 시간 5초 설정\n",
    "\n",
    "# 페이지 불러오기\n",
    "driver.get('https://www.wanted.co.kr/wdlist/523?country=kr&job_sort=job.recommend_order&years=-1&locations=all')  # 직무 선택된 URL\n",
    "\n",
    "# 자동 스크롤 기능 구현\n",
    "def scroll_to_bottom():\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # 페이지 로드 대기\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    time.sleep(5)  # 추가 대기 시간 (페이지가 완전히 로드될 때까지 기다림)\n",
    "\n",
    "# 스크롤을 끝까지 내린다\n",
    "scroll_to_bottom()\n",
    "\n",
    "# 공고 리스트의 모든 링크를 저장 (스크롤 후 모든 공고 리스트 가져오기)\n",
    "job_links = driver.find_elements(By.CSS_SELECTOR, 'ul.List_List__Ni_dK li a')\n",
    "job_urls = [job.get_attribute('href') for job in job_links]  # 모든 공고의 링크를 저장\n",
    "\n",
    "# 페이지 상단으로 다시 스크롤\n",
    "driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "\n",
    "try:\n",
    "    # 수집한 데이터를 CSV로 작성할 때, UTF-8 인코딩 확인\n",
    "    with open(\"C:/Users/USER/Desktop/MBA_정호원/원티드_채용공고_마케팅.csv\", 'w', newline='', encoding='utf-8-sig') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['채용공고명', '포지션 상세', '주요 업무', '자격 요건', '우대사항', '혜택 및 복지', '채용 전형', '태그', '마감일', '면접리뷰', '회사위치', '회사명'])  # CSV 헤더 설정\n",
    "\n",
    "        for job_url in job_urls:\n",
    "            try:\n",
    "                driver.get(job_url)\n",
    "                time.sleep(2)  # 페이지 로딩 대기\n",
    "\n",
    "                # 버튼 텍스트를 비교하여 \"상세 정보 더 보기\" 버튼 클릭\n",
    "                try:\n",
    "                    more_buttons = driver.find_elements(By.XPATH, '//button/span')\n",
    "                    for button in more_buttons:\n",
    "                        if button.text == \"상세 정보 더 보기\":\n",
    "                            button.click()\n",
    "                            time.sleep(1)  # 버튼을 클릭한 후 대기\n",
    "                            break\n",
    "                except:\n",
    "                    print(f\"'상세 정보 더 보기' 버튼을 찾을 수 없음 : {job_url}. Continuing...\")\n",
    "\n",
    "                # 채용공고명\n",
    "                try:\n",
    "                    title = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/header/h1').text\n",
    "                except:\n",
    "                    title = \"\"\n",
    "\n",
    "                # 포지션 상세\n",
    "                try:\n",
    "                    details = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/p/span').text\n",
    "                except:\n",
    "                    details = \"\"\n",
    "\n",
    "                # 주요 업무\n",
    "                try:\n",
    "                    main_tasks = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[1]/p').text\n",
    "                except:\n",
    "                    main_tasks = \"\"\n",
    "\n",
    "                # 자격 요건\n",
    "                try:\n",
    "                    qualifications = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[1]/p/span').text\n",
    "                except:\n",
    "                    qualifications = \"\"\n",
    "\n",
    "                # 우대사항\n",
    "                try:\n",
    "                    preferred = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[3]/p/span').text\n",
    "                except:\n",
    "                    preferred = \"\"\n",
    "\n",
    "                # 혜택 및 복지\n",
    "                try:\n",
    "                    benefits = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[4]/p/span').text\n",
    "                except:\n",
    "                    benefits = \"\"\n",
    "\n",
    "                # 채용 전형\n",
    "                try:\n",
    "                    process = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[1]/div/div[5]/p').text\n",
    "                except:\n",
    "                    process = \"\"\n",
    "\n",
    "                # 태그 정보 추출\n",
    "                try:\n",
    "                    tags_ul = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[2]/ul/li')\n",
    "                    tags = [tag.text for tag in tags_ul]  \n",
    "                    tags_text = ', '.join(tags)  # 태그를 ,로 연결\n",
    "                except:\n",
    "                    tags_text = \"\"\n",
    "\n",
    "                # 마감일\n",
    "                try:\n",
    "                    deadline = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[3]/span').text\n",
    "                except:\n",
    "                    deadline = \"\"\n",
    "\n",
    "                # 면접 리뷰 정보 추출\n",
    "                try:\n",
    "                    interview_review_elements = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[4]/ul/li/span')\n",
    "                    interview_reviews = [review.text for review in interview_review_elements]\n",
    "                    interview_review_text = ', '.join(interview_reviews)  # ,로 연결\n",
    "                except:\n",
    "                    interview_review_text = \"\"\n",
    "\n",
    "                # 위치 정보 추출\n",
    "                try:\n",
    "                    location = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/section/article[5]/div/div[2]/span').text\n",
    "                except:\n",
    "                    # 대체 위치 정보 추출\n",
    "                    try:\n",
    "                        location = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/header/div/div[1]/span[2]').text\n",
    "                    except:\n",
    "                        location = \"위치 정보 없음\"  # 위치가 없을 경우 기본값 설정\n",
    "\n",
    "                # 회사명\n",
    "                try:\n",
    "                    company_name = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[1]/div/section/header/div/div[1]/a').text\n",
    "                except:\n",
    "                    company_name = \"\"\n",
    "\n",
    "                # 수집한 데이터를 CSV 파일에 작성\n",
    "                writer.writerow([title, details, main_tasks, qualifications, preferred, benefits, process, tags_text, deadline, interview_review_text, location, company_name])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing job {job_url}: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
